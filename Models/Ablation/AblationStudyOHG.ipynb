{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 8106,
     "status": "ok",
     "timestamp": 1743010762947,
     "user": {
      "displayName": "Carter Smith",
      "userId": "16068926545987539689"
     },
     "user_tz": 300
    },
    "id": "JLWCPXV7bpnu"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import random\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import math\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "executionInfo": {
     "elapsed": 48,
     "status": "ok",
     "timestamp": 1743010763027,
     "user": {
      "displayName": "Carter Smith",
      "userId": "16068926545987539689"
     },
     "user_tz": 300
    },
    "id": "JOI-cjpxiAdu",
    "outputId": "3c733209-b611-44b2-b828-dd77a8830cd2"
   },
   "outputs": [],
   "source": [
    "torch.version.cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 29,
     "status": "ok",
     "timestamp": 1743010763058,
     "user": {
      "displayName": "Carter Smith",
      "userId": "16068926545987539689"
     },
     "user_tz": 300
    },
    "id": "mjKmP6NjbrVv",
    "outputId": "87568342-103b-4699-c9bb-66b0b3466ec0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Script is running WITHOUT GPU\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "  device = torch.device(\"cuda\")\n",
    "  print('Script is running with GPU')\n",
    "else:\n",
    "  device = torch.device(\"cpu\")\n",
    "  print('Script is running WITHOUT GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1743010763078,
     "user": {
      "displayName": "Carter Smith",
      "userId": "16068926545987539689"
     },
     "user_tz": 300
    },
    "id": "8DBAewO8iAdz",
    "outputId": "5bedd466-b511-4911-ada8-f2bc12b39069"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1743010763083,
     "user": {
      "displayName": "Carter Smith",
      "userId": "16068926545987539689"
     },
     "user_tz": 300
    },
    "id": "gxTpg9Zrdtmh"
   },
   "outputs": [],
   "source": [
    "def calculate_class_weights(y):\n",
    "    unique_classes, class_counts = np.unique(y, return_counts=True)\n",
    "    total_samples = len(y)\n",
    "    class_weights = []\n",
    "    class_weights.append(1)\n",
    "\n",
    "    for class_label, class_count in zip(unique_classes, class_counts):\n",
    "        class_weight = math.log(total_samples / (class_count))\n",
    "        class_weights.append(class_weight)\n",
    "\n",
    "    class_weights = torch.tensor(class_weights, dtype=torch.float32).to(device)\n",
    "\n",
    "    return class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1743010763091,
     "user": {
      "displayName": "Carter Smith",
      "userId": "16068926545987539689"
     },
     "user_tz": 300
    },
    "id": "OFG0VTkBeHRO"
   },
   "outputs": [],
   "source": [
    "def predict(model, data, pad_idx):\n",
    "    with torch.no_grad():\n",
    "      predicts_out = []\n",
    "      tags_out = []\n",
    "      text_out = []\n",
    "      for batch in data:\n",
    "        text = batch[0]\n",
    "        output = batch[1]\n",
    "        output = output.transpose(0,1)\n",
    "        tags = output[0]\n",
    "        mask = output[1]\n",
    "        predictions = model.forward(text)\n",
    "        predictions = predictions.transpose(1,2)\n",
    "        predictions = predictions.argmax(dim = 1)\n",
    "        for idx, sent in enumerate(text):\n",
    "          predicts_out.append(np.asarray(predictions[idx].cpu()))\n",
    "          tags_out.append(np.asarray(tags[idx].cpu()))\n",
    "          text_out.append(np.asarray(sent.cpu()))\n",
    "    for idx, ele in enumerate(predicts_out):\n",
    "      predicts_out[idx] = predicts_out[idx].tolist()\n",
    "    for idx, ele in enumerate(tags_out):\n",
    "      tags_out[idx] = tags_out[idx].tolist()\n",
    "    for idx, ele in enumerate(text_out):\n",
    "      text_out[idx] = text_out[idx].tolist()\n",
    "\n",
    "    return predicts_out, tags_out, text_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 314
    },
    "executionInfo": {
     "elapsed": 19,
     "status": "error",
     "timestamp": 1743010777636,
     "user": {
      "displayName": "Carter Smith",
      "userId": "16068926545987539689"
     },
     "user_tz": 300
    },
    "id": "Dzjjb9j_b61c",
    "outputId": "7d6bf093-d16a-4d46-9448-95af198455a0"
   },
   "outputs": [],
   "source": [
    "base_sents = list(np.load('OHG_sents.npy', allow_pickle=True))\n",
    "base_tags = list(np.load('OHG_tags_minimal.npy', allow_pickle=True))\n",
    "problems = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18853"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(base_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 8663,
     "status": "aborted",
     "timestamp": 1743010763281,
     "user": {
      "displayName": "Carter Smith",
      "userId": "16068926545987539689"
     },
     "user_tz": 300
    },
    "id": "hqD-nAXPb3mb"
   },
   "outputs": [],
   "source": [
    "sample_sizes = [250, 500, 750, 1000, 1500, 2000, 2500, 3000, 3500, 4000, 4500, 5000, 7500, 10000, 18853]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 8773,
     "status": "aborted",
     "timestamp": 1743010763392,
     "user": {
      "displayName": "Carter Smith",
      "userId": "16068926545987539689"
     },
     "user_tz": 300
    },
    "id": "p7XDSAldcfdy"
   },
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(columns=[\"tag\", \"accuracy\", \"sample_size\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "2ab1COwJbug4",
    "outputId": "3ad37e16-556e-47cd-a38a-e68d20e23dc5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "CPU times: total: 2.08 s\n",
      "Wall time: 2.92 s\n",
      "CPU times: total: 953 ms\n",
      "Wall time: 1 s\n",
      "CPU times: total: 1.09 s\n",
      "Wall time: 1.17 s\n",
      "CPU times: total: 1.11 s\n",
      "Wall time: 1.2 s\n",
      "CPU times: total: 1.38 s\n",
      "Wall time: 1.52 s\n",
      "CPU times: total: 1.64 s\n",
      "Wall time: 1.73 s\n",
      "1\n",
      "CPU times: total: 734 ms\n",
      "Wall time: 754 ms\n",
      "CPU times: total: 969 ms\n",
      "Wall time: 1.1 s\n",
      "CPU times: total: 1.09 s\n",
      "Wall time: 1.21 s\n",
      "CPU times: total: 1.28 s\n",
      "Wall time: 1.33 s\n",
      "CPU times: total: 1.25 s\n",
      "Wall time: 1.3 s\n",
      "CPU times: total: 1.59 s\n",
      "Wall time: 1.63 s\n",
      "2\n",
      "CPU times: total: 656 ms\n",
      "Wall time: 706 ms\n",
      "CPU times: total: 953 ms\n",
      "Wall time: 970 ms\n",
      "CPU times: total: 1.17 s\n",
      "Wall time: 1.3 s\n",
      "CPU times: total: 1.23 s\n",
      "Wall time: 1.27 s\n",
      "CPU times: total: 1.66 s\n",
      "Wall time: 1.76 s\n",
      "CPU times: total: 1.58 s\n",
      "Wall time: 1.69 s\n",
      "3\n",
      "CPU times: total: 734 ms\n",
      "Wall time: 758 ms\n",
      "CPU times: total: 922 ms\n",
      "Wall time: 914 ms\n",
      "CPU times: total: 1.08 s\n",
      "Wall time: 1.15 s\n",
      "CPU times: total: 1.23 s\n",
      "Wall time: 1.3 s\n",
      "CPU times: total: 1.44 s\n",
      "Wall time: 1.6 s\n",
      "CPU times: total: 1.69 s\n",
      "Wall time: 1.88 s\n",
      "4\n",
      "CPU times: total: 797 ms\n",
      "Wall time: 871 ms\n",
      "CPU times: total: 812 ms\n",
      "Wall time: 922 ms\n",
      "CPU times: total: 969 ms\n",
      "Wall time: 1.11 s\n",
      "CPU times: total: 1.27 s\n",
      "Wall time: 1.28 s\n",
      "CPU times: total: 1.52 s\n",
      "Wall time: 1.61 s\n",
      "CPU times: total: 1.86 s\n",
      "Wall time: 2.06 s\n",
      "5\n",
      "CPU times: total: 828 ms\n",
      "Wall time: 884 ms\n",
      "CPU times: total: 1.2 s\n",
      "Wall time: 1.32 s\n",
      "CPU times: total: 1.31 s\n",
      "Wall time: 1.42 s\n",
      "CPU times: total: 1.23 s\n",
      "Wall time: 1.31 s\n",
      "CPU times: total: 1.42 s\n",
      "Wall time: 1.6 s\n",
      "CPU times: total: 2 s\n",
      "Wall time: 2.16 s\n",
      "6\n",
      "CPU times: total: 828 ms\n",
      "Wall time: 896 ms\n",
      "CPU times: total: 953 ms\n",
      "Wall time: 1.1 s\n",
      "CPU times: total: 1.03 s\n",
      "Wall time: 1.28 s\n",
      "CPU times: total: 1.22 s\n",
      "Wall time: 1.36 s\n",
      "CPU times: total: 1.45 s\n",
      "Wall time: 1.52 s\n",
      "CPU times: total: 1.81 s\n",
      "Wall time: 1.86 s\n",
      "7\n",
      "CPU times: total: 797 ms\n",
      "Wall time: 808 ms\n",
      "CPU times: total: 1.02 s\n",
      "Wall time: 1.07 s\n",
      "CPU times: total: 984 ms\n",
      "Wall time: 1.05 s\n",
      "CPU times: total: 1.45 s\n",
      "Wall time: 1.55 s\n",
      "CPU times: total: 1.59 s\n",
      "Wall time: 1.67 s\n",
      "CPU times: total: 1.66 s\n",
      "Wall time: 1.78 s\n",
      "8\n",
      "CPU times: total: 844 ms\n",
      "Wall time: 877 ms\n",
      "CPU times: total: 953 ms\n",
      "Wall time: 1.04 s\n",
      "CPU times: total: 1.09 s\n",
      "Wall time: 1.16 s\n",
      "CPU times: total: 1.11 s\n",
      "Wall time: 1.26 s\n",
      "CPU times: total: 1.36 s\n",
      "Wall time: 1.62 s\n",
      "CPU times: total: 1.81 s\n",
      "Wall time: 2.03 s\n",
      "9\n",
      "CPU times: total: 891 ms\n",
      "Wall time: 937 ms\n",
      "CPU times: total: 1.08 s\n",
      "Wall time: 1.09 s\n",
      "CPU times: total: 1.58 s\n",
      "Wall time: 1.68 s\n",
      "CPU times: total: 1.44 s\n",
      "Wall time: 1.53 s\n",
      "CPU times: total: 1.47 s\n",
      "Wall time: 1.75 s\n",
      "CPU times: total: 1.84 s\n",
      "Wall time: 2.14 s\n",
      "10\n",
      "CPU times: total: 828 ms\n",
      "Wall time: 848 ms\n",
      "CPU times: total: 1.05 s\n",
      "Wall time: 1.07 s\n",
      "CPU times: total: 1.14 s\n",
      "Wall time: 1.24 s\n",
      "CPU times: total: 1.59 s\n",
      "Wall time: 1.7 s\n",
      "CPU times: total: 1.89 s\n",
      "Wall time: 2.08 s\n",
      "CPU times: total: 2 s\n",
      "Wall time: 2.21 s\n",
      "11\n",
      "CPU times: total: 844 ms\n",
      "Wall time: 861 ms\n",
      "CPU times: total: 1.16 s\n",
      "Wall time: 1.24 s\n",
      "CPU times: total: 1.19 s\n",
      "Wall time: 1.36 s\n",
      "CPU times: total: 1.33 s\n",
      "Wall time: 1.48 s\n",
      "CPU times: total: 1.42 s\n",
      "Wall time: 1.68 s\n",
      "CPU times: total: 1.92 s\n",
      "Wall time: 2.06 s\n",
      "12\n",
      "CPU times: total: 797 ms\n",
      "Wall time: 811 ms\n",
      "CPU times: total: 1.03 s\n",
      "Wall time: 1.06 s\n",
      "CPU times: total: 1.53 s\n",
      "Wall time: 1.71 s\n",
      "CPU times: total: 1.59 s\n",
      "Wall time: 1.76 s\n",
      "CPU times: total: 2.12 s\n",
      "Wall time: 2.4 s\n",
      "CPU times: total: 1.81 s\n",
      "Wall time: 1.92 s\n",
      "13\n",
      "CPU times: total: 859 ms\n",
      "Wall time: 852 ms\n",
      "CPU times: total: 1.14 s\n",
      "Wall time: 1.17 s\n",
      "CPU times: total: 1.36 s\n",
      "Wall time: 1.37 s\n",
      "CPU times: total: 1.42 s\n",
      "Wall time: 1.47 s\n",
      "CPU times: total: 2 s\n",
      "Wall time: 2.04 s\n",
      "CPU times: total: 1.88 s\n",
      "Wall time: 2.07 s\n",
      "14\n",
      "CPU times: total: 953 ms\n",
      "Wall time: 995 ms\n",
      "CPU times: total: 1.09 s\n",
      "Wall time: 1.13 s\n",
      "CPU times: total: 1.22 s\n",
      "Wall time: 1.33 s\n",
      "CPU times: total: 1.45 s\n",
      "Wall time: 1.51 s\n",
      "CPU times: total: 1.89 s\n",
      "Wall time: 1.96 s\n",
      "CPU times: total: 2.03 s\n",
      "Wall time: 2.03 s\n"
     ]
    }
   ],
   "source": [
    "iteration = 0\n",
    "while iteration < 100:\n",
    "  print(iteration)\n",
    "  for size in sample_sizes:\n",
    "    random_indices = random.sample(range(len(base_sents)), size)\n",
    "    sents = []\n",
    "    tags = []\n",
    "    for index in random_indices:\n",
    "      sents.append(base_sents[index])\n",
    "      tags.append(base_tags[index])\n",
    "\n",
    "    for idx, sent in enumerate(sents):\n",
    "      sent.insert(0, 'start')\n",
    "      sent.append('stop')\n",
    "      sents[idx] = sent\n",
    "    for idx, sent in enumerate(tags):\n",
    "      sent.insert(0, 'start')\n",
    "      sent.append('stop')\n",
    "      tags[idx] = sent\n",
    "\n",
    "\n",
    "    rawwords = []\n",
    "    for sent in sents:\n",
    "      for word in sent:\n",
    "        rawwords.append(word)\n",
    "\n",
    "    rawtags = []\n",
    "    for sequence in tags:\n",
    "      for tag in sequence:\n",
    "        rawtags.append(tag)\n",
    "\n",
    "    allwords = list(set(rawwords))\n",
    "    alltags = list(set(rawtags))\n",
    "\n",
    "    word_tokenizer = {word: idx+1 for idx, word in enumerate(allwords)}\n",
    "    word_decoder = {idx+1: word for idx, word in enumerate(allwords)}\n",
    "    tag_tokenizer = {tag: idx+1 for idx, tag in enumerate(alltags)}\n",
    "    tag_decoder = {idx+1: tag for idx, tag in enumerate(alltags)}\n",
    "\n",
    "    def tokenize(sentences, tokenizer):\n",
    "      indexed_sentences = []\n",
    "      for sentence in sentences:\n",
    "        indexed_sentence = [tokenizer[word] for word in sentence]\n",
    "        indexed_sentences.append(indexed_sentence)\n",
    "      return indexed_sentences\n",
    "\n",
    "    encsents = tokenize(sents, word_tokenizer)\n",
    "    enctags = tokenize(tags, tag_tokenizer)\n",
    "\n",
    "    padsents, padtags = [], []\n",
    "\n",
    "    maxlen = max(len(sublist) for sublist in encsents)\n",
    "    for sublist in encsents:\n",
    "      while len(sublist) < maxlen:\n",
    "        sublist = sublist + [0]\n",
    "        if len(sublist) == maxlen:\n",
    "          break\n",
    "        sublist = [0] + sublist\n",
    "      padsents.append(sublist)\n",
    "    allenctags = []\n",
    "    maxlen = max(len(sublist) for sublist in enctags)\n",
    "    for sublist in enctags:\n",
    "      for i in sublist:\n",
    "        allenctags.append(i)\n",
    "      while len(sublist) < maxlen:\n",
    "        sublist = sublist + [0]\n",
    "        if len(sublist) == maxlen:\n",
    "          break\n",
    "        sublist = [0] + sublist\n",
    "      padtags.append(sublist)\n",
    "\n",
    "    tag_mask = []\n",
    "    for seq in padtags:\n",
    "      mask = [1]*len(seq)\n",
    "      for idx, tag in enumerate(seq):\n",
    "        if 'XX' in list(tag_tokenizer.keys()):\n",
    "          if tag == tag_tokenizer['XX']:\n",
    "            mask[idx] = 0\n",
    "        if tag == tag_tokenizer['start']:\n",
    "          mask[idx] = 0\n",
    "        if tag == tag_tokenizer['stop']:\n",
    "          mask[idx] = 0\n",
    "        if tag == tag_tokenizer['PUNCT']:\n",
    "          mask[idx] = 0\n",
    "      tag_mask.append(mask)\n",
    "    for i in range(len(tag_mask)):\n",
    "      if len(tag_mask[i]) != len(padsents[i]):\n",
    "        print(i)\n",
    "    pad_tags_mask = []\n",
    "    for i in range(len(padtags)):\n",
    "      pad_tags_mask.append([padtags[i], tag_mask[i]])\n",
    "    X_test, X_train, y_test, y_train = train_test_split(padsents, pad_tags_mask, test_size=0.8)\n",
    "    X_train_tensor = torch.tensor(X_train, dtype=torch.long).to(device)\n",
    "    y_train_tensor = torch.tensor(y_train, dtype=torch.long).to(device)\n",
    "    X_test_tensor = torch.tensor(X_test, dtype=torch.long).to(device)\n",
    "    y_test_tensor = torch.tensor(y_test, dtype=torch.long).to(device)\n",
    "    train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "    test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "    batch_size = 64\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "    class_weights = calculate_class_weights(allenctags)\n",
    "\n",
    "    class Model(nn.Module):\n",
    "      def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "      def categorical_accuracy(self, preds, y, mask, tag_pad_idx = 0):\n",
    "        max_preds = preds.argmax(dim = 1, keepdim = False)\n",
    "        max_preds = max_preds*mask\n",
    "        y = y*mask\n",
    "        max_preds = torch.flatten(max_preds)\n",
    "        y = torch.flatten(y)\n",
    "        non_pad_elements = y.nonzero()\n",
    "        correct = max_preds[non_pad_elements].eq(y[non_pad_elements])\n",
    "        return correct.sum() / y[non_pad_elements].shape[0]\n",
    "\n",
    "      def early_stop(self, validation_loss, patience = 3, min_delta = 0):\n",
    "        if validation_loss < self.min_validation_loss:\n",
    "            self.min_validation_loss = validation_loss\n",
    "            self.patiencecount = 0\n",
    "        elif validation_loss > (self.min_validation_loss + min_delta):\n",
    "            self.patiencecount += 1\n",
    "            #print(f\"Early stopping counter: {self.patiencecount} out of {patience}\")\n",
    "            if self.patiencecount >= patience:\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "      def fit(self, train_dl, val_dl, epochs, pad_idx = 0):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr = 0.001)\n",
    "\n",
    "        self.patiencecount = 0\n",
    "        self.min_validation_loss = float('inf')\n",
    "\n",
    "        self.trainlosses = []\n",
    "        self.vallosses = []\n",
    "\n",
    "        self.train_accs = []\n",
    "        self.val_accs = []\n",
    "\n",
    "        counter = 0\n",
    "        for epoch in range(epochs):\n",
    "          for batch in train_dl:\n",
    "            counter += 1\n",
    "            text = batch[0]\n",
    "\n",
    "            output = batch[1]\n",
    "            output = output.transpose(0,1)\n",
    "            tags = output[0]\n",
    "            mask = output[1]\n",
    "            optimizer.zero_grad()\n",
    "            predictions = self.forward(text)\n",
    "            predictions = predictions.transpose(1,2)\n",
    "            loss = self.loss_fn(predictions, tags)\n",
    "            loss = (loss * mask).sum() / mask.sum()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "          train_loss, train_acc = self.evaluate(train_dl)\n",
    "          val_loss, val_acc = self.evaluate(val_dl)\n",
    "          self.trainlosses.append(train_loss)\n",
    "          self.vallosses.append(val_loss)\n",
    "          self.train_accs.append(train_acc)\n",
    "          self.val_accs.append(val_acc)\n",
    "          if self.early_stop(val_loss):\n",
    "            break\n",
    "          train_acc = train_acc*100\n",
    "          val_acc = val_acc*100\n",
    "          #print(f\"Epoch [{epoch + 1}/{epochs}] - TrainLoss: {train_loss:.4f}, ValLoss: {val_loss:.4f}, TrainAcc: {train_acc:.2f},% ValAcc: {val_acc:.2f}%\")\n",
    "\n",
    "      def evaluate(self, val_dl, pad_idx = 0):\n",
    "        losses = []\n",
    "        accuracies = []\n",
    "        with torch.no_grad():\n",
    "          for batch in val_dl:\n",
    "              text = batch[0]\n",
    "              output = batch[1]\n",
    "              output = output.transpose(0,1)\n",
    "              tags = output[0]\n",
    "              mask = output[1]\n",
    "              predictions = self.forward(text)\n",
    "              predictions = predictions.transpose(1,2)\n",
    "              loss = self.loss_fn(predictions, tags)\n",
    "              loss = (loss * mask).sum() / mask.sum()\n",
    "              losses.append(loss)\n",
    "              acc = self.categorical_accuracy(predictions, tags, mask, pad_idx)\n",
    "              accuracies.append(acc)\n",
    "        return torch.Tensor(losses).mean(), torch.Tensor(accuracies).mean()\n",
    "\n",
    "\n",
    "    class OHGTagger(Model):\n",
    "        def __init__(self, vocab, embeds, hidden, tagset, n_layers, dropout, criterion, pad_idx = 0):\n",
    "            super().__init__()\n",
    "\n",
    "            self.embedding = nn.Embedding(vocab, embeds, padding_idx = pad_idx, scale_grad_by_freq = True)\n",
    "\n",
    "            self.lstm = nn.LSTM(embeds, hidden, num_layers = n_layers, bidirectional = True,\n",
    "                                dropout = dropout if n_layers > 1 else 0)\n",
    "\n",
    "            self.lin = nn.Linear(hidden * 2, tagset)\n",
    "\n",
    "            self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "            self.loss_fn = criterion\n",
    "\n",
    "        def forward(self, sent):\n",
    "            x = self.embedding(sent)\n",
    "            x, (hidden, cell) = self.lstm(x)\n",
    "            x = self.lin(self.dropout(x))\n",
    "            return x\n",
    "\n",
    "    vocab = len(allwords)+1\n",
    "    n_emb = 300\n",
    "    n_hidden = 60\n",
    "    n_tags = len(alltags)+1\n",
    "    n_layers = 3\n",
    "    dropout = .2\n",
    "    pad_idx = 0\n",
    "    criterion = nn.CrossEntropyLoss(reduction = 'none', weight = class_weights, ignore_index = pad_idx).to(device)\n",
    "\n",
    "    network_OHGTagger = OHGTagger(vocab, n_emb, n_hidden, n_tags, n_layers, dropout, criterion, pad_idx).to(device)\n",
    "\n",
    "    %time network_OHGTagger.fit(train_loader, test_loader, 100)\n",
    "\n",
    "    preds, tags, texts = predict(network_OHGTagger, test_loader, pad_idx)\n",
    "\n",
    "    for i in range(len(preds)):\n",
    "      for j in range(len(preds[i])):\n",
    "        if tags[i][j] == 0:\n",
    "          preds[i][j] = 0\n",
    "      preds[i] = [ele for ele in preds[i] if ele != 0]\n",
    "      tags[i] = [ele for ele in tags[i] if ele != 0]\n",
    "      texts[i] = [ele for ele in texts[i] if ele != 0]\n",
    "    decpreds, dectags, dectext, declangs = [], [], [], []\n",
    "    decpreds.append(tokenize(preds, tag_decoder))\n",
    "    dectags.append(tokenize(tags, tag_decoder))\n",
    "    dectext.append(tokenize(texts, word_decoder))\n",
    "    decpreds = decpreds[0]\n",
    "    dectags = dectags[0]\n",
    "    dectext = dectext[0]\n",
    "\n",
    "\n",
    "    corrects, incorrects, totals = [], [], []\n",
    "\n",
    "    for i in range(len(decpreds)):\n",
    "      for j in range(len(decpreds[i])):\n",
    "        totals.append(dectags[i][j])\n",
    "        if decpreds[i][j] == dectags[i][j]:\n",
    "          corrects.append(decpreds[i][j])\n",
    "        else:\n",
    "          incorrects.append(decpreds[i][j])\n",
    "\n",
    "\n",
    "    c_freqs = Counter(corrects)\n",
    "    ic_freqs = Counter(incorrects)\n",
    "    t_freqs = Counter(totals)\n",
    "\n",
    "\n",
    "    data = []\n",
    "    labels = []\n",
    "    outs = []\n",
    "    any_c = [x[0] for x in c_freqs.most_common()]\n",
    "    for i in t_freqs.most_common():\n",
    "      if i[0] not in any_c:\n",
    "        data.append(0)\n",
    "        labels.append(i[0])\n",
    "        outs.append((i[0], 0))\n",
    "        results_df.loc[len(results_df)] = [i[0], 0, size]\n",
    "      else:\n",
    "        for ele in c_freqs.most_common():\n",
    "          if ele[0] == i[0]:\n",
    "            num_c = ele[1]\n",
    "        class_acc = num_c/i[1]\n",
    "        data.append(class_acc*100)\n",
    "        labels.append(i[0])\n",
    "        outs.append((i[0], class_acc*100))\n",
    "        results_df.loc[len(results_df)] = [i[0], class_acc*100, size]\n",
    "\n",
    "  results_df.to_csv('resultsOHG_test.csv', index=False)\n",
    "  with torch.no_grad():\n",
    "      torch.cuda.empty_cache()\n",
    "  iteration = iteration + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Rwd9TQ0AfLjg"
   },
   "outputs": [],
   "source": [
    "results_df.to_csv('resultsOHG_tes.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
